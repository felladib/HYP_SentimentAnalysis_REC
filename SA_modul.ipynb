{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felladib/H_SentimentAnalysis_REC/blob/main/SA_modul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMZqeqb7rsEm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkaLAIf4hGoV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import metrics\n",
        "from keras.layers import Embedding, Multiply, Dense, Dot, Conv2D, Input, Flatten\n",
        "from keras.layers import concatenate\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njL9EYfxlcb2"
      },
      "outputs": [],
      "source": [
        "!pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqyYg-PVlazk",
        "outputId": "394883e8-1a44-41b9-daf9-c64d5c6de56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from flair.data import Sentence\n",
        "import pickle\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uizFP_8bxw6p"
      },
      "source": [
        "# **collection de données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4e5LcxH3OfZ"
      },
      "source": [
        "**SA_data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYpZjdLmx8r4"
      },
      "outputs": [],
      "source": [
        "#ouvrir le dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/IMDB/IMDB_Dataset.csv')\n",
        "#ouvrir le fichier du vocab\n",
        "with  open('/content/drive/MyDrive/IMDB/IMDB_vocab',\"rb\") as file:\n",
        "      tokens = pickle.load(file)\n",
        "#ouvrir le fichier de la matrice d'embeddings\n",
        "with  open('/content/drive/MyDrive/IMDB/IMDB_embd',\"rb\") as file:\n",
        "      mat = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzO_TsIUv-gK"
      },
      "source": [
        "# **preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO60-mqKa57N"
      },
      "outputs": [],
      "source": [
        "def clean_doc(doc):#fonction pour nettoyer les commentaires\n",
        "    # split into tokens by white space\n",
        "    tokens = doc.split()\n",
        "    # remove punctuation from each token\n",
        "    table = str.maketrans('', '', punctuation)\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    # filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    # filter out short tokens\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "    tokens = [word.lower() for word in tokens ]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI6dx5a4wu_o",
        "outputId": "4766179e-2c37-4ce5-87fd-0dcf232dc520"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1480"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#nettoyer les reviews dans le dataset\n",
        "data['review']=data['review'].apply(clean_doc)\n",
        "#calculer le nombre de mot maximum dans une review\n",
        "MAX_SEQUENCE_LENGTH=max(data.applymap(lambda x: len(x)).max())\n",
        "MAX_SEQUENCE_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4u-7Tx1bHMc",
        "outputId": "abaa5aa4-c266-473c-d700-b5a0f3ea572c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#transformer data['sentiment'] en 0 et 1 ==> 0 : négative / 1 : positive\n",
        "lb=LabelBinarizer()\n",
        "sentiment_data=lb.fit_transform(data['sentiment'])\n",
        "sentiment_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7rlCnz2bMWJ"
      },
      "outputs": [],
      "source": [
        "#Découper le dataset en training set et test set\n",
        "#train set (40000 row)\n",
        "X_train_rev=data.review[:40000]\n",
        "y_train_rev=sentiment_data[:40000]\n",
        "#test_set (10000 rows)\n",
        "X_test_rev=data.review[40000:45000]\n",
        "y_test_rev=sentiment_data[40000:45000]\n",
        "#valid_set (10000 rows)\n",
        "X_val_rev=data.review[45000:]\n",
        "y_val_rev=sentiment_data[45000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUhYeZscbOek"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer()\n",
        "token.word_index = tokens\n",
        "\n",
        "pad=token.texts_to_sequences(X_train_rev)\n",
        "#token.texts_to_sequences(train_reviews) method is called to convert each review in the train_reviews list\n",
        "#into a sequence of integers using the word_index property of the token object.\n",
        "\n",
        "X_train_rev= pad_sequences(pad, maxlen=1480, padding='post')\n",
        "#pad_sequences(pad, maxlen=1480, padding='post') function is called to pad the sequences in pad variable\n",
        "# to a maximum length of 1480. This is done to ensure that all sequences have the same length.\n",
        "\n",
        "pad=token.texts_to_sequences(X_test_rev)\n",
        "X_test_rev= pad_sequences(pad, maxlen=1480, padding='post')\n",
        "\n",
        "pad=token.texts_to_sequences(X_val_rev)\n",
        "X_val_rev= pad_sequences(pad, maxlen=1480, padding='post')\n",
        "#entrainement des modèles\n",
        "length=1480\n",
        "vocab_size=len(tokens)+1\n",
        "# model=define_lstm(length,vocab_size,mat,16)\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mae','accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT0dqAQn-eWd",
        "outputId": "43dd1dbe-da30-430e-987d-a3c5845289c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    1,     2,     3, ...,     0,     0,     0],\n",
              "       [  150,   151,   152, ...,     0,     0,     0],\n",
              "       [  221,   150,   222, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [   31,    27,  3868, ...,     0,     0,     0],\n",
              "       [   15,    91,   302, ...,     0,     0,     0],\n",
              "       [10621,  6386, 23136, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train_rev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob76zFWvjXzn"
      },
      "source": [
        "# **module d'analyse de sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yq5fu-x98UX"
      },
      "outputs": [],
      "source": [
        "#Metrics\n",
        "from keras import metrics\n",
        "rmse = metrics.RootMeanSquaredError()\n",
        "precision = metrics.Precision()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhuG2S1Xj7bA"
      },
      "source": [
        "## **classe LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLSTM(tf.keras.Model):\n",
        "    def __init__(self,units,vocab_size,mat,l1=0,l2=0 , droup_val=0):\n",
        "        super(MyLSTM, self).__init__()\n",
        "        self.embedding           = Embedding(vocab_size, 768,weights=[mat], trainable=True)\n",
        "        self.dropout1            = tf.keras.layers.Dropout(0.5 , name='dropout')\n",
        "        self.lstm                = tf.keras.layers.LSTM(units,\n",
        "                                                        return_sequences=True,\n",
        "                                                        #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                        name='lstm1')\n",
        "        self.attention           = tf.keras.layers.Attention()\n",
        "        self.dropout             = tf.keras.layers.Dropout(droup_val , name='dropout')\n",
        "        self.flatten             = tf.keras.layers.Flatten(name='flatten')\n",
        "        self.dense1              = tf.keras.layers.Dense(128,\n",
        "                                                         #kernel_regularizer=tf.keras.regularizers.l2(l2=l2),\n",
        "                                                         activation='tanh', name='dense1')\n",
        "        self.dense3              = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name ='output')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.lstm(x)\n",
        "        x = self.attention([x , x])\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense3(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "HF18COxFwktY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqgh8nsCl_xb"
      },
      "source": [
        "**entrainement LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQLhHbPSmMHx"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 20\n",
        "droup_val =0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdoT6NtkmDig"
      },
      "outputs": [],
      "source": [
        "model_sa=MyLSTM(units,vocab_size,mat,droup_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgo9JPQZml91"
      },
      "outputs": [],
      "source": [
        "model_sa.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=[precision,'mae', metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR1rtcccvvA-"
      },
      "outputs": [],
      "source": [
        "history = model_sa.fit(X_train_rev, y_train_rev, epochs=EPOCHS, batch_size= BATCH_SIZE, validation_data=(X_val_rev, y_val_rev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt4plq7geOF3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_curve= history.history[\"loss\"]\n",
        "acc_curve = history.history[\"precision_1\"]\n",
        "rmse_curve= history.history[\"root_mean_squared_error\"]\n",
        "mae_curve = history.history[\"mae\"]\n",
        "\n",
        "loss_val = history.history[\"val_loss\"]\n",
        "acc_val  = history.history[\"val_precision_1\"]\n",
        "rmse_val = history.history[\"val_root_mean_squared_error\"]\n",
        "mae_val  = history.history[\"val_mae\"]\n",
        "\n",
        "# ploter loss function\n",
        "def ploter(title , curve , valid):\n",
        "  plt.plot(curve , label = \"train\")\n",
        "  plt.plot(valid , label = \"validation\")\n",
        "  plt.ylim(0, 1)\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "ploter('loss' , loss_curve , loss_val)\n",
        "ploter('rmse' , rmse_curve , rmse_val)\n",
        "ploter('mae' , mae_curve , mae_val)\n",
        "ploter('acc' , acc_curve , acc_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXAGDE9ZWpLf"
      },
      "source": [
        "**test LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVzpW-qgedD7"
      },
      "outputs": [],
      "source": [
        "score = model_sa.evaluate(X_test_rev , y_test_rev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLEiljUAelk8"
      },
      "outputs": [],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ZPBjE6SAdK"
      },
      "source": [
        "## **classe BiLstm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbu-ZQC-SAdL"
      },
      "outputs": [],
      "source": [
        "class MyBiLstm(tf.keras.Model):\n",
        "        def __init__(self,units,vocab_size,mat,l1=0,l2=0 , droup_val=0):\n",
        "            super(MyBiLstm, self).__init__()\n",
        "            self.embedding           = Embedding(vocab_size, 768,weights=[mat], trainable=True)\n",
        "            self.dropout1            = tf.keras.layers.Dropout(0.5 , name='dropout')\n",
        "            self.bilstm              = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(int(units/2),\n",
        "                                                                    return_sequences=True,\n",
        "                                                                    # input_shape=(None , 128 , 768),\n",
        "                                                                    #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                                    name='bilstm1'))\n",
        "            self.attention           = tf.keras.layers.Attention()\n",
        "            self.dropout             = tf.keras.layers.Dropout(droup_val)\n",
        "            self.flatten             = tf.keras.layers.Flatten()\n",
        "            self.dense1              = tf.keras.layers.Dense(128,\n",
        "                                                             #kernel_regularizer=tf.keras.regularizers.l2(l2=l2),\n",
        "                                                             activation='tanh')\n",
        "            self.dense2              = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name ='output')\n",
        "\n",
        "\n",
        "        def call(self, inputs):\n",
        "            x = self.embedding(inputs)\n",
        "            x = self.dropout1(x)\n",
        "            x = self.bilstm(x)\n",
        "            x = self.attention([x , x])\n",
        "            x = self.dropout(x)\n",
        "            x = self.flatten(x)\n",
        "            x = self.dense1(x)\n",
        "            return self.dense2(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kit5FsK-SAdL"
      },
      "source": [
        "**Entrainement BiLSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjgJfqJ0HEnU"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 20\n",
        "droup_val =0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaqLrZrWHEnU"
      },
      "outputs": [],
      "source": [
        "model_sa=MyBiLstm(units,vocab_size,mat, droup_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwJM7xUnHEnU"
      },
      "outputs": [],
      "source": [
        "model_sa.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss='binary_crossentropy', metrics=[precision,'mae', metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlquTR_AHEnV"
      },
      "outputs": [],
      "source": [
        "history = model_sa.fit(X_train_rev, y_train_rev, epochs=EPOCHS, batch_size= BATCH_SIZE, validation_data=(X_val_rev, y_val_rev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQEbViKHEnV"
      },
      "source": [
        "**test BiLstm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id0aePAMHEnV"
      },
      "outputs": [],
      "source": [
        "scores= model_sa.evaluate(X_test_rev,y_test_rev,verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "cBO8qbwQyjTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmRCIn4BHEnV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_curve= history.history[\"loss\"]\n",
        "acc_curve = history.history[\"precision\"]\n",
        "rmse_curve= history.history[\"root_mean_squared_error\"]\n",
        "mae_curve = history.history[\"mae\"]\n",
        "\n",
        "loss_val = history.history[\"val_loss\"]\n",
        "acc_val  = history.history[\"val_precision\"]\n",
        "rmse_val = history.history[\"val_root_mean_squared_error\"]\n",
        "mae_val  = history.history[\"val_mae\"]\n",
        "\n",
        "# ploter loss function\n",
        "def ploter(title , curve , valid):\n",
        "  plt.plot(curve , label = \"train\")\n",
        "  plt.plot(valid , label = \"validation\")\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "ploter('loss' , loss_curve , loss_val)\n",
        "ploter('rmse' , rmse_curve , rmse_val)\n",
        "ploter('mae' , mae_curve , mae_val)\n",
        "ploter('acc' , acc_curve , acc_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icicUZkpkRCn"
      },
      "source": [
        "## **classe BiLstmCnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5rY4CzEkQaT"
      },
      "outputs": [],
      "source": [
        "class MyBiLstmCnn(tf.keras.Model):\n",
        "        def __init__(self,units,vocab_size,mat,l1=0,l2=0 , droup_val=0):\n",
        "            super(MyBiLstmCnn, self).__init__()\n",
        "            self.embedding       = Embedding(vocab_size, 768,weights=[mat], trainable=True)\n",
        "            self.dropout1        = tf.keras.layers.Dropout(0.5)\n",
        "            self.bilstm          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(int(units/2),\n",
        "                                                                    return_sequences=True,\n",
        "                                                                    # input_shape=(None , 128 , 768),\n",
        "                                                                    # kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                                    name='bilstm1'))\n",
        "            self.cnn              = tf.keras.layers.Conv1D(64,3,activation=\"relu\",padding=\"valid\")\n",
        "            self.attention        = tf.keras.layers.Attention()\n",
        "            self.dropout2         = tf.keras.layers.Dropout(droup_val)\n",
        "            self.flatten          = tf.keras.layers.Flatten()\n",
        "            self.dense1           = tf.keras.layers.Dense(128,activation='tanh')\n",
        "            self.dense3           = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name ='output')\n",
        "\n",
        "\n",
        "        def call(self, inputs):\n",
        "            x = self.embedding(inputs)\n",
        "            x = self.dropout1(x)\n",
        "            x = self.bilstm(x)\n",
        "            x = self.cnn(x)\n",
        "            x = self.attention([x , x])\n",
        "            x = self.dropout2(x)\n",
        "            x = self.flatten(x)\n",
        "            x = self.dense1(x)\n",
        "            return self.dense3(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqVwxRpuoH8l"
      },
      "source": [
        "**TEST Bilstm cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYNth7e5oH8m"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "droup_val = 0.4\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkXKRWG9oH8n"
      },
      "outputs": [],
      "source": [
        "model_sa=MyBiLstmCnn(units,vocab_size,mat, droup_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPxsyYJYoH8n"
      },
      "outputs": [],
      "source": [
        "model_sa.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=[precision,'mae', metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6SFZHSEkTbew"
      },
      "outputs": [],
      "source": [
        "history = model_sa.fit(X_train_rev, y_train_rev, epochs=EPOCH, batch_size= BATCH_SIZE, validation_data=(X_val_rev, y_val_rev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rkv2GK_qUHd0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_curve= history.history[\"loss\"]\n",
        "acc_curve = history.history[\"precision\"]\n",
        "rmse_curve= history.history[\"root_mean_squared_error\"]\n",
        "mae_curve = history.history[\"mae\"]\n",
        "\n",
        "loss_val = history.history[\"val_loss\"]\n",
        "acc_val  = history.history[\"val_precision\"]\n",
        "rmse_val = history.history[\"val_root_mean_squared_error\"]\n",
        "mae_val  = history.history[\"val_mae\"]\n",
        "\n",
        "# ploter loss function\n",
        "def ploter(title , curve , valid):\n",
        "  plt.plot(curve , label = \"train\")\n",
        "  plt.plot(valid , label = \"validation\")\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.ylim(0,1)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "ploter('loss' , loss_curve , loss_val)\n",
        "ploter('rmse' , rmse_curve , rmse_val)\n",
        "ploter('mae' , mae_curve , mae_val)\n",
        "ploter('acc' , acc_curve , acc_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g74nuqpsXn8J"
      },
      "source": [
        "**test BiLstm_Cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3ov7TmnLmhtv"
      },
      "outputs": [],
      "source": [
        "score = model_sa.evaluate(X_test_rev , y_test_rev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "plCypCUCmoCA"
      },
      "outputs": [],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VsCeLGRsTAgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeUmU9jPlYAW"
      },
      "source": [
        "## **classe BiLstmRnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZNKNcW_lYiM"
      },
      "outputs": [],
      "source": [
        "class MyBiLstmRnn(tf.keras.Model):\n",
        "        def __init__(self,units,vocab_size,mat,l1=0,l2=0 , droup_val=0):\n",
        "            super(MyBiLstmRnn, self).__init__()\n",
        "            self.embedding           = Embedding(vocab_size, 768,weights=[mat], trainable=True)\n",
        "            self.dropout1            = tf.keras.layers.Dropout(0.5)\n",
        "            self.bilstm              = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(int(units/2),\n",
        "                                                                    return_sequences=True,\n",
        "                                                                    #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                                    name='bilstm1'))\n",
        "\n",
        "            self.rnn                 = tf.keras.layers.SimpleRNN(int(units/2),\n",
        "                                                        return_sequences=True ,\n",
        "                                                        #input_shape=(None , 128 , 768),\n",
        "                                                        #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                        name = 'rnn1')\n",
        "            self.attention           = tf.keras.layers.Attention()\n",
        "            self.dropout             = tf.keras.layers.Dropout(droup_val)\n",
        "            self.flatten             = tf.keras.layers.Flatten()\n",
        "            self.dense1              = tf.keras.layers.Dense(128,\n",
        "                                                             #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                             activation='tanh')\n",
        "            self.dense3              = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name ='output')\n",
        "\n",
        "\n",
        "        def call(self, inputs):\n",
        "            x = self.embedding(inputs)\n",
        "            x = self.dropout1(x)\n",
        "            x = self.bilstm(x)\n",
        "            x = self.rnn(x)\n",
        "            x = self.attention([x , x])\n",
        "            x = self.dropout(x)\n",
        "            x = self.flatten(x)\n",
        "            x = self.dense1(x)\n",
        "            return self.dense3(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdzjLVwJ9J1D"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "droup_val = 0.3\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMe4neU89J1E"
      },
      "outputs": [],
      "source": [
        "model_sa=MyBiLstmRnn(units,vocab_size,mat, droup_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlpHJM559J1E"
      },
      "outputs": [],
      "source": [
        "model_sa.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss='binary_crossentropy', metrics=[precision,'mae', metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUjUQ-RR9J1E"
      },
      "outputs": [],
      "source": [
        "history = model_sa.fit(X_train_rev, y_train_rev, epochs=EPOCHS, batch_size= BATCH_SIZE, validation_data=(X_val_rev, y_val_rev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnU9cL_H9J1E"
      },
      "source": [
        "**test BiLstm_Rnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpHwuNjk9J1F"
      },
      "outputs": [],
      "source": [
        "scores = model_sa.evaluate(X_test_rev , y_test_rev)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "u7rS7Mkb9J1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbHH-Qwm9J1E"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_curve= history.history[\"loss\"]\n",
        "acc_curve = history.history[\"precision\"]\n",
        "rmse_curve= history.history[\"root_mean_squared_error\"]\n",
        "mae_curve = history.history[\"mae\"]\n",
        "\n",
        "loss_val = history.history[\"val_loss\"]\n",
        "acc_val  = history.history[\"val_precision\"]\n",
        "rmse_val = history.history[\"val_root_mean_squared_error\"]\n",
        "mae_val  = history.history[\"val_mae\"]\n",
        "\n",
        "# ploter loss function\n",
        "def ploter(title , curve , valid):\n",
        "  plt.plot(curve , label = \"train\")\n",
        "  plt.plot(valid , label = \"validation\")\n",
        "  plt.ylim(0, 1)\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "ploter('loss' , loss_curve , loss_val)\n",
        "ploter('rmse' , rmse_curve , rmse_val)\n",
        "ploter('mae' , mae_curve , mae_val)\n",
        "ploter('acc' , acc_curve , acc_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQK_8H0amJdl"
      },
      "source": [
        "## **classe LstmCnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ecJrqBKmKJ_"
      },
      "outputs": [],
      "source": [
        "class MyLstmCnn(tf.keras.Model):\n",
        "    def __init__(self,units,vocab_size,mat,l1=0,l2=0 , droup_val=0):\n",
        "        super(MyLstmCnn, self).__init__()\n",
        "        self.embedding       = Embedding(vocab_size, 768,weights=[mat], trainable=True)\n",
        "        self.dropout1        = tf.keras.layers.Dropout(0.5)\n",
        "        self.lstm                = tf.keras.layers.LSTM(units,\n",
        "                                               return_sequences=True,\n",
        "                                              #  input_shape=(None , 128 , 768),\n",
        "                                              #  kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                               dropout=0.2 ,\n",
        "                                               name = 'lstm1')\n",
        "        self.cnn                 = tf.keras.layers.Conv1D(64,3,activation=\"relu\",padding=\"valid\")\n",
        "        self.attention           = tf.keras.layers.Attention()\n",
        "        self.dropout2             = tf.keras.layers.Dropout((droup_val))\n",
        "        self.flatten             = tf.keras.layers.Flatten()\n",
        "        self.dense1              = tf.keras.layers.Dense(128,\n",
        "                                                        #  kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                         activation='tanh')\n",
        "        self.dense3              = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name =' output')\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.lstm(x)\n",
        "        x = self.cnn (x)\n",
        "        x = self.attention([x,x])\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense3(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDxUvZVfoKIQ"
      },
      "source": [
        "**Entrainment LSTM CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laRpWf5fZzYn"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "droup_val = 0.3\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucr2FO5sZzYo"
      },
      "outputs": [],
      "source": [
        "model_sa=MyLstmCnn(units,vocab_size,mat,droup_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGp-4RO_ZzYo"
      },
      "outputs": [],
      "source": [
        "model_sa.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "                 loss='binary_crossentropy',\n",
        "                 metrics=[precision,'mae', metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR4yWoApZzYo"
      },
      "outputs": [],
      "source": [
        "history = model_sa.fit(X_train_rev,\n",
        "                       y_train_rev,\n",
        "                       epochs=EPOCH,\n",
        "                       batch_size= BATCH_SIZE,\n",
        "                       validation_data=(X_val_rev, y_val_rev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7mXDxaCb_1p"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_curve= history.history[\"loss\"]\n",
        "acc_curve = history.history[\"precision\"]\n",
        "rmse_curve= history.history[\"root_mean_squared_error\"]\n",
        "mae_curve = history.history[\"mae\"]\n",
        "\n",
        "loss_val = history.history[\"val_loss\"]\n",
        "acc_val  = history.history[\"val_precision\"]\n",
        "rmse_val = history.history[\"val_root_mean_squared_error\"]\n",
        "mae_val  = history.history[\"val_mae\"]\n",
        "\n",
        "# ploter loss function\n",
        "def ploter(title , curve , valid):\n",
        "  plt.plot(curve , label = \"train\")\n",
        "  plt.plot(valid , label = \"validation\")\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "ploter('loss' , loss_curve , loss_val)\n",
        "ploter('rmse' , rmse_curve , rmse_val)\n",
        "ploter('mae' , mae_curve , mae_val)\n",
        "ploter('acc' , acc_curve , acc_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdlLH8FBZDgP"
      },
      "source": [
        "**test Lstm_Cnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GTw0nK2cA0N"
      },
      "outputs": [],
      "source": [
        "scores = model_sa.evaluate(X_test_rev , y_test_rev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EclmIBWNZI34"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOVFWgiUUb65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGZ2ycH4mKwK"
      },
      "source": [
        "## **classe LstmRnn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WePSmBOrmLGJ"
      },
      "outputs": [],
      "source": [
        "class MyLstmRnn(tf.keras.Model):\n",
        "    def __init__(self,units,vocab_size,mat,l1=0,l2=0 , droup_val=0):\n",
        "        super(MyLstmRnn, self).__init__()\n",
        "        self.embedding           = Embedding(vocab_size, 768,weights=[mat], trainable=True)\n",
        "        self.dropout1            = tf.keras.layers.Dropout(0.5 , name='dropout')\n",
        "        self.lstm                = tf.keras.layers.LSTM(units,\n",
        "                                                      return_sequences=True,\n",
        "                                                      #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                      #input_shape=(None ,128 , 768),\n",
        "                                                      name='lstm1')\n",
        "\n",
        "        self.rnn                 = tf.keras.layers.SimpleRNN(int(units/2),\n",
        "                                                              return_sequences=True,\n",
        "                                                              #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                              name = 'rnn1')\n",
        "        self.attention           = tf.keras.layers.Attention()\n",
        "        self.dropout             = tf.keras.layers.Dropout(droup_val)\n",
        "        self.flatten             = tf.keras.layers.Flatten()\n",
        "        self.dense1              = tf.keras.layers.Dense(128,\n",
        "                                                         #kernel_regularizer=tf.keras.regularizers.L1L2(l1=l1, l2=l2),\n",
        "                                                         activation='tanh')\n",
        "        self.dense3              = tf.keras.layers.Dense(1 , activation = 'sigmoid' , name ='output')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.lstm(x)\n",
        "        x = self.rnn(x)\n",
        "        x = self.attention([x , x])\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense3(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G773qYoSU1vF"
      },
      "source": [
        "**Entrainment LSTM RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D0wzbqJZFMI"
      },
      "outputs": [],
      "source": [
        "units = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "droup_val =0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEU4AC4PZFMI"
      },
      "outputs": [],
      "source": [
        "model_sa=MyLstmRnn(units,vocab_size,mat,droup_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY9Ehq4vZFMJ"
      },
      "outputs": [],
      "source": [
        "model_sa.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss='binary_crossentropy', metrics=[precision,'mae', metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_sa.fit(X_train_rev, y_train_rev, epochs=EPOCHS, batch_size= BATCH_SIZE, validation_data=(X_val_rev, y_val_rev))"
      ],
      "metadata": {
        "id": "RQJjLTDhdCxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK_CNqydZFMJ"
      },
      "source": [
        "**test LSTM RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6BHvIvlZFMJ"
      },
      "outputs": [],
      "source": [
        "score = model_sa.evaluate(X_test_rev , y_test_rev)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "Pu7hZhJZZFMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIpmWJ4mZFMJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_curve= history.history[\"loss\"]\n",
        "acc_curve = history.history[\"precision\"]\n",
        "rmse_curve= history.history[\"root_mean_squared_error\"]\n",
        "mae_curve = history.history[\"mae\"]\n",
        "\n",
        "loss_val = history.history[\"val_loss\"]\n",
        "acc_val  = history.history[\"val_precision\"]\n",
        "rmse_val = history.history[\"val_root_mean_squared_error\"]\n",
        "mae_val  = history.history[\"val_mae\"]\n",
        "\n",
        "# ploter loss function\n",
        "def ploter(title , curve , valid):\n",
        "  plt.plot(curve , label = \"train\")\n",
        "  plt.plot(valid , label = \"validation\")\n",
        "  plt.ylim(0, 1)\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "ploter('loss' , loss_curve , loss_val)\n",
        "ploter('rmse' , rmse_curve , rmse_val)\n",
        "ploter('mae' , mae_curve , mae_val)\n",
        "ploter('acc' , acc_curve , acc_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHO3St6wzcyz"
      },
      "source": [
        "## ***save sentiment model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62SnON3V-dUp"
      },
      "outputs": [],
      "source": [
        "model_sa.save('/content/drive/MyDrive/concat_modelCASA', save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BdTnzt_6hsl"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/Our_Datasets/Yelp/yelp_normalized_dataset(55738).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qamHSITt9drn"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0As9RFc8Ha4d"
      },
      "outputs": [],
      "source": [
        "loaded_model_SA = tf.keras.models.load_model('/content/drive/MyDrive/concat_modelCASA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S15bJqTG_u-0"
      },
      "outputs": [],
      "source": [
        "sentiment = loaded_model_SA.predict(dataset['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAbywGAwLoow"
      },
      "outputs": [],
      "source": [
        "sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl5bqU3FIc8-"
      },
      "outputs": [],
      "source": [
        "dataset['sentiment']= sentiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/yelp_normalized_dataset(55738).csv')"
      ],
      "metadata": {
        "id": "QWgaK17Az2K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ql19IInWlNuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hKMPneTZG618"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "values , counts = np.unique( matrice_de_confiance , return_counts = True) #verification que la matrice a ete bien rempli\n",
        "print(values , counts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vWKpo0v6lPRl"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}