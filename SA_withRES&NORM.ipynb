{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnbq5kVDJLK9RVE7w06dJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felladib/H_SentimentAnalysis_REC/blob/main/SA_withRES%26NORM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D52SFqpA7jY-"
      },
      "source": [
        "# **Sentiment model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqgTiZYR832_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Concatenate, LayerNormalization, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGqkogef7rln"
      },
      "outputs": [],
      "source": [
        "class AddNorm(tf.keras.layers.Layer):\n",
        "    \"\"\"Residual connection followed by layer normalization.\"\"\"\n",
        "\n",
        "    def __init__(self, name=None, **kwargs):\n",
        "        super().__init__()\n",
        "        if name: self._name = name\n",
        "        self.ln = LayerNormalization(**kwargs)\n",
        "        self.add = Add()\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.ln(self.add(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiWii28p7qbN"
      },
      "outputs": [],
      "source": [
        "from keras.backend import dropout\n",
        "class HybLstm(Model):\n",
        "  def __init__(self,units,preprocessing_model,l1=0,l2=0):\n",
        "    super().__init__()\n",
        "    self.preprocessing_model = preprocessing_model\n",
        "    self.first_layer = Dense(units,activation='relu')\n",
        "    self.lstm1 = Bidirectional(LSTM(int(units/2), return_sequences=True, kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2) , dropout = 0.5))\n",
        "    self.lstm2 = Bidirectional(LSTM(int(units/2), return_sequences=True, kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2) , dropout = 0.5))\n",
        "    self.lstm3 = LSTM(units, return_sequences=True, return_state=True, kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2) , dropout = 0.5)\n",
        "\n",
        "    self.add1,self.add2 = AddNorm(),AddNorm()\n",
        "\n",
        "    self.concat = Concatenate()\n",
        "    self.dense1 = Dense(units,activation='relu')\n",
        "    self.final_layer = Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "  def call(self,x):\n",
        "    x  = self.preprocessing_model(x)\n",
        "    x  = self.first_layer(x)\n",
        "    xl = self.lstm1(x)\n",
        "    x  = self.add1([x,xl])\n",
        "    xl = self.lstm2(x)\n",
        "    x  = self.add2([x,xl])\n",
        "\n",
        "    _, final_memory_state, final_carry_state  = self.lstm3(x)\n",
        "    states = self.concat([final_memory_state, final_carry_state])\n",
        "    states = self.dense1(states)\n",
        "    out    = self.final_layer(states)\n",
        "    return out\n",
        "\n",
        "  def train(self,X_train,Y_train, batch_size , epochs, learning_rate,**kwargs):\n",
        "    print(\"    training ...\")\n",
        "    # Learning rate decay\n",
        "    callbacks = []\n",
        "    def scheduler(epoch, lr):\n",
        "      if epoch<2:\n",
        "        return learning_rate/10\n",
        "      else:\n",
        "        return learning_rate * np.exp(-4 * epoch / epochs)\n",
        "\n",
        "    callbacks.append(tf.keras.callbacks.LearningRateScheduler(scheduler))\n",
        "\n",
        "    # Compile the model :\n",
        "    self.compile(loss='binary_crossentropy' ,\n",
        "                 optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                 metrics = [\"accuracy\" , rmse , 'mae' , precision])\n",
        "    # Fitting the data :\n",
        "    self.train_history = self.fit(X_train,Y_train,\n",
        "                                  batch_size = BATCH_SIZE,\n",
        "                                  epochs=EPOCHS,\n",
        "                                  callbacks=callbacks,\n",
        "                                  ** kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9Ux6knf9BJd"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "LEARNING_RATE = 5e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9rAx1267veR"
      },
      "outputs": [],
      "source": [
        "model = HybLstm(units=32,preprocessing_model=preprocessing_model,l1=1e-5,l2=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqBS3Bs_7zU4",
        "outputId": "7330c3b2-4b14-4fb9-e96c-39391a77c632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    training ...\n",
            "Epoch 1/15\n",
            "1250/1250 [==============================] - 581s 455ms/step - loss: 0.4644 - accuracy: 0.7822 - root_mean_squared_error: 0.3508 - mae: 0.2905 - precision: 0.8189 - val_loss: 0.4924 - val_accuracy: 0.7864 - val_root_mean_squared_error: 0.3938 - val_mae: 0.2458 - val_precision: 0.9238 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.3612 - accuracy: 0.8468 - root_mean_squared_error: 0.3294 - mae: 0.2171 - precision: 0.8440 - val_loss: 0.3459 - val_accuracy: 0.8572 - val_root_mean_squared_error: 0.3224 - val_mae: 0.2165 - val_precision: 0.8644 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.3559 - accuracy: 0.8512 - root_mean_squared_error: 0.3268 - mae: 0.2138 - precision: 0.8503 - val_loss: 0.3530 - val_accuracy: 0.8536 - val_root_mean_squared_error: 0.3267 - val_mae: 0.1961 - val_precision: 0.8148 - lr: 0.0029\n",
            "Epoch 4/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.3276 - accuracy: 0.8621 - root_mean_squared_error: 0.3135 - mae: 0.1966 - precision: 0.8627 - val_loss: 0.3413 - val_accuracy: 0.8664 - val_root_mean_squared_error: 0.3188 - val_mae: 0.2353 - val_precision: 0.8617 - lr: 0.0022\n",
            "Epoch 5/15\n",
            "1250/1250 [==============================] - 564s 452ms/step - loss: 0.3080 - accuracy: 0.8715 - root_mean_squared_error: 0.3032 - mae: 0.1841 - precision: 0.8700 - val_loss: 0.3155 - val_accuracy: 0.8730 - val_root_mean_squared_error: 0.3069 - val_mae: 0.1717 - val_precision: 0.8793 - lr: 0.0017\n",
            "Epoch 6/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.2934 - accuracy: 0.8788 - root_mean_squared_error: 0.2954 - mae: 0.1744 - precision: 0.8767 - val_loss: 0.3212 - val_accuracy: 0.8588 - val_root_mean_squared_error: 0.3129 - val_mae: 0.2063 - val_precision: 0.8165 - lr: 0.0013\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.2792 - accuracy: 0.8852 - root_mean_squared_error: 0.2874 - mae: 0.1654 - precision: 0.8831 - val_loss: 0.3021 - val_accuracy: 0.8706 - val_root_mean_squared_error: 0.3021 - val_mae: 0.1848 - val_precision: 0.8570 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.2682 - accuracy: 0.8909 - root_mean_squared_error: 0.2815 - mae: 0.1587 - precision: 0.8882 - val_loss: 0.3177 - val_accuracy: 0.8690 - val_root_mean_squared_error: 0.3093 - val_mae: 0.1704 - val_precision: 0.8409 - lr: 7.7319e-04\n",
            "Epoch 9/15\n",
            "1250/1250 [==============================] - 541s 433ms/step - loss: 0.2571 - accuracy: 0.8955 - root_mean_squared_error: 0.2751 - mae: 0.1513 - precision: 0.8928 - val_loss: 0.3100 - val_accuracy: 0.8754 - val_root_mean_squared_error: 0.3049 - val_mae: 0.1659 - val_precision: 0.8750 - lr: 5.9221e-04\n",
            "Epoch 10/15\n",
            "1250/1250 [==============================] - 563s 450ms/step - loss: 0.2461 - accuracy: 0.9021 - root_mean_squared_error: 0.2684 - mae: 0.1439 - precision: 0.8977 - val_loss: 0.3073 - val_accuracy: 0.8718 - val_root_mean_squared_error: 0.3051 - val_mae: 0.1748 - val_precision: 0.8775 - lr: 4.5359e-04\n",
            "Epoch 11/15\n",
            "1250/1250 [==============================] - 558s 447ms/step - loss: 0.2380 - accuracy: 0.9051 - root_mean_squared_error: 0.2635 - mae: 0.1391 - precision: 0.9005 - val_loss: 0.3148 - val_accuracy: 0.8740 - val_root_mean_squared_error: 0.3058 - val_mae: 0.1605 - val_precision: 0.8771 - lr: 3.4742e-04\n",
            "Epoch 12/15\n",
            "1250/1250 [==============================] - 563s 451ms/step - loss: 0.2290 - accuracy: 0.9090 - root_mean_squared_error: 0.2579 - mae: 0.1334 - precision: 0.9068 - val_loss: 0.3138 - val_accuracy: 0.8720 - val_root_mean_squared_error: 0.3064 - val_mae: 0.1674 - val_precision: 0.8784 - lr: 2.6610e-04\n",
            "Epoch 13/15\n",
            "1250/1250 [==============================] - 539s 431ms/step - loss: 0.2239 - accuracy: 0.9118 - root_mean_squared_error: 0.2547 - mae: 0.1303 - precision: 0.9082 - val_loss: 0.3252 - val_accuracy: 0.8742 - val_root_mean_squared_error: 0.3075 - val_mae: 0.1553 - val_precision: 0.8817 - lr: 2.0381e-04\n",
            "Epoch 14/15\n",
            " 876/1250 [====================>.........] - ETA: 2:23 - loss: 0.2222 - accuracy: 0.9123 - root_mean_squared_error: 0.2527 - mae: 0.1280 - precision: 0.9093"
          ]
        }
      ],
      "source": [
        "history = model.train(X_train_rev,y_train_rev, batch_size = BATCH_SIZE, epochs=EPOCHS, learning_rate=LEARNING_RATE , validation_data=(X_val_rev , y_val_rev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8r1mCfCj8rP",
        "outputId": "54dde834-ffc2-4b82-e10c-fa1affc6f560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 59s 374ms/step - loss: 0.5945 - accuracy: 0.8592 - root_mean_squared_error: 0.3496 - mae: 0.1451 - precision: 0.8547\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5945040583610535,\n",
              " 0.8592000007629395,\n",
              " 0.34960469603538513,\n",
              " 0.14513042569160461,\n",
              " 0.8546671867370605]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test_rev , y_test_rev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s97l8vbNkaFA"
      },
      "source": [
        "overfitting\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOE0YsLizrgR"
      },
      "outputs": [],
      "source": [
        "from keras import metrics\n",
        "rmse = metrics.RootMeanSquaredError()\n",
        "precision = metrics.Precision()"
      ]
    }
  ]
}